# lasso-
LASSO 回归优化算法性能对比实验报告
实验人
2025 年 12 月 14 日

目录
实验概述

1.1 实验背景

1.2 实验目标

1.3 实验环境

实验设计

2.1 算法选型与参数优化

2.2 数据集设计

2.3 评价指标

实验结果

3.1 核心性能指标汇总

3.2 分场景性能对比

3.3 维度扩展性分析

实验结果分析

4.1 效率维度分析

4.2 精度维度分析

4.3 收敛速度维度分析

结论与建议

5.1 核心结论

5.2 工程选型建议

5.3 实验局限性与改进方向

附录

6.1 核心代码说明

6.2 实验可重复性

6.3 符号说明

1 实验概述
1.1 实验背景
LASSO（Least Absolute Shrinkage and Selection Operator）回归作为经典的稀疏正则化方法，被广泛应用于特征选择和参数估计。其核心优化目标为：

min
⁡
β
1
2
n
∥
X
β
−
y
∥
2
2
+
λ
∥
β
∥
1
β
min
​
  
2n
1
​
 ∥Xβ−y∥ 
2
2
​
 +λ∥β∥ 
1
​
 
不同优化算法在求解 LASSO 问题时，效率、精度、收敛性存在显著差异。本实验旨在对比 6 种主流 LASSO 优化算法的性能，量化各算法在不同数据规模下的表现，为工程选型提供依据。

1.2 实验目标
对比 ADMM、BCD、SGD、次梯度下降、FISTA、Huber 损失近似点梯度 6 种算法的计算效率、迭代次数、模型精度；

验证各算法在低维到超高维、小样本到超大样本场景下的适配性；

优化算法参数，确保每种算法达到理论最优性能；

基于实验结果给出 LASSO 回归算法选型建议。

1.3 实验环境
硬件：Intel Core i7-12700H CPU，32GB DDR4 内存；

软件：Python 3.9，NumPy 1.24，Scikit-learn 1.2，Matplotlib 3.7；

操作系统：Windows 11 专业版（64 位）；

编译器：PyCharm 2023.2，TeX Live 2023。

2 实验设计
2.1 算法选型与参数优化
2.1.1 核心算法列表
表 1: 6 种 LASSO 优化算法核心信息

算法名称	核心原理	优化策略
ADMM（交替方向乘子法）	增广拉格朗日函数分解，变量交替更新	动态调整 rho 参数，自适应平衡原始/对偶残差
BCD（块坐标下降）	分块更新变量，结合活跃集策略减少计算量	仅更新非零系数维度，降低迭代复杂度
SGD（随机梯度下降）	单样本/小批量梯度更新，动量加速	小批量（32 样本）+ 学习率慢衰减 + 参数裁剪
次梯度下降	L1 正则化次梯度更新，动量加速	指数衰减学习率，平衡收敛速度与稳定性
FISTA（快速近似点梯度）	Nesterov 加速 + 近似点算子，收敛速率 $O(1/k^2)$	自适应调整 Lipschitz 常数，限制最大调整次数
Huber 损失近似点梯度	Huber 鲁棒损失 + 近似点算子，平衡 L1/L2 损失特性	自适应 Lipschitz 常数，$\delta = 1.0$ 平衡鲁棒性与精度
2.1.2 参数优化方案
采用网格搜索法对各算法核心参数调优，最优参数配置如下：

表 2: 各算法最优参数配置

算法名称	最优参数配置
ADMM	$\rho = 1.0, \tau = 1.618$, 启用自适应 rho 调整，tol = $10^{-6}$
BCD	启用活跃集策略，tol = $10^{-6}$, 仅更新非零系数维度
SGD	初始学习率 $\eta = 1.0$, 动量 $\gamma = 0.9$, 小批量大小 =32, 学习率衰减 $\eta_k = \eta_0/\sqrt{k+1}$
次梯度下降	初始学习率 $\eta = 0.01$, 衰减率 $\gamma = 0.995$, 动量 $\gamma = 0.8$
FISTA	初始 Lipschitz 常数 $L = 1.0$, 调整系数 $\gamma = 1.5$, 最大调整次数 =5
Huber 损失近似点梯度	$\delta = 1.0, L = 1.0, \gamma = 1.2$, 最大调整次数 =5
2.2 数据集设计
生成标准化 LASSO 回归合成数据集，覆盖 5 种典型数据规模：

表 3: 实验数据集配置

编号	样本数 (n)	特征数 (p)	稀疏比	噪声水平	数据分布	用途
1	100	20	0.3	0.1	正态分布	小样本低维场景
2	500	50	0.3	0.1	正态分布	中样本中维场景
3	1000	100	0.3	0.1	正态分布	大样本中维场景
4	1000	500	0.3	0.1	正态分布	大样本高维场景
5	5000	1000	0.3	0.1	正态分布	超大样本超高维场景
2.3 评价指标
实验采用 4 类核心评价指标：

计算效率：平均训练时间（秒），重复 3 次实验取均值；

收敛速度：算法收敛所需的平均迭代次数；

模型精度：与 Scikit-learn Lasso 最优解的均方误差（MSE）；

维度扩展性：训练时间随特征数 $p$ 的变化趋势。

3 实验结果
3.1 核心性能指标汇总
表 4: 6 种算法核心性能指标汇总

算法	平均耗时（秒）	平均迭代次数	平均 MSE	效率排名	精度排名	综合排名
BCD	0.052	12	0.0018	1	1	1
Huber 损失近似点梯度	0.333	23	$2 \times 10^{-7}$	2	2	2
FISTA	0.275	33	$1 \times 10^{-7}$	3	3	3
SGD	0.258	423	$3.36 \times 10^{-5}$	4	4	4
次梯度下降	0.600	531	$1 \times 10^{-7}$	5	3	5
ADMM	10.279	307	0.0018	6	1	6
3.2 分场景性能对比
3.2.1 小样本低维场景（100,20）
表 5: 小样本低维场景性能对比

算法	耗时（秒）	迭代次数	MSE
BCD	0.0013	8	0.002099
Huber 损失近似点梯度	0.0033	25	$0 \times 10^{-8}$
FISTA	0.0037	34	$0 \times 10^{-8}$
SGD	0.0680	496	$7 \times 10^{-6}$
次梯度下降	0.0230	450	$0 \times 10^{-8}$
ADMM	0.0111	117	0.002099
3.2.2 超大样本超高维场景（5000,1000）
表 6: 超大样本超高维场景性能对比

算法	耗时（秒）	迭代次数	MSE
BCD	0.1437	12	0.000979
Huber 损失近似点梯度	1.2962	17	$0 \times 10^{-8}$
FISTA	1.0276	19	$0 \times 10^{-8}$
SGD	0.5597	315	$1 \times 10^{-6}$
次梯度下降	2.0974	647	$0 \times 10^{-8}$
ADMM	38.4634	566	0.000979
3.3 维度扩展性分析
图 1: 各算法训练时间随特征数变化趋势

维度扩展性核心结论：

BCD/Huber/FISTA：训练时间随特征数线性增长（$O(p)$），$p = 1000$ 时耗时 <1.5 秒；

SGD/次梯度下降：训练时间随特征数亚线性增长（$O(p^{0.5})$），$p = 1000$ 时耗时 <2.1 秒；

ADMM：训练时间随特征数立方增长（$O(p^3)$），$p = 1000$ 时耗时达 38.46 秒（是 BCD 的 267 倍）。

4 实验结果分析
4.1 效率维度分析
BCD 绝对领先：全场景下速度最快，高维场景仅 0.14 秒，核心优势为活跃集策略大幅减少计算维度；

FISTA/Huber 效率接近：中高维场景耗时 0.28-1.3 秒，是次梯度下降的 2 倍；

SGD 修复后效率提升：迭代次数从 1000 次降至 315-671 次，高维场景耗时从 1.04 秒降至 0.56 秒；

ADMM 高维效率极差：矩阵求逆操作（$O(p^3)$）导致高维场景效率瓶颈，仅低维场景可用。

4.2 精度维度分析
BCD/ADMM 精度最高且稳定：MSE 0.001-0.002，不受数据规模影响；

FISTA/次梯度/Huber 精度接近：MSE $10^{-7}$，低维场景达到浮点精度级最优；

SGD 修复后精度正常：MSE 从 $10^{38}$ 降至 $10^{-6}$，与其他算法无数量级差距。

4.3 收敛速度维度分析
BCD 迭代次数最少：仅 8-24 次，是 FISTA 的 1/3、SGD 的 1/35；

FISTA 收敛速度快：迭代次数 33 次，是次梯度下降的 1/16；

SGD 迭代次数仍偏高：需 315-671 次，但已能提前收敛（非固定 1000 次）。

5 结论与建议
5.1 核心结论
BCD 是 LASSO 回归最优工程方案：效率、精度、收敛速度全面领先，无明显短板；

FISTA 是次优选择：效率-精度权衡最优，适合无法使用活跃集的扩展场景；

SGD 仅适合分布式超大样本场景：单机场景无优势，需配合小批量策略保证精度；

ADMM/次梯度下降无工程价值：仅适合教学/理论研究，工业界应优先选择 BCD/FISTA；

Huber 损失近似点梯度适合噪声数据：鲁棒性强，精度接近 FISTA，适合含异常值的场景。

5.2 工程选型建议
表 7: LASSO 回归算法工程选型建议

应用场景	推荐算法	核心理由
全场景（尤其高维）	BCD	速度最快、精度最高、迭代次数最少
高维大数据 + 实时性要求高	FISTA	效率-精度权衡最优、易实现、收敛速度快
含异常值/噪声数据	Huber 损失近似点梯度	鲁棒性强、精度接近 FISTA
分布式超大样本(n>10 万)	SGD	易并行化、内存占用低，配合小批量策略保证精度
低维 + 超高精度要求	ADMM	收敛理论保证强、精度稳定（仅低维场景推荐）
教学演示/简单场景	次梯度下降	实现最简单、理论门槛低
5.3 实验局限性与改进方向
5.3.1 局限性
仅使用合成数据集，未验证真实数据集（如金融/医疗数据）；

正则化强度固定（$\lambda = 0.1$），未测试不同正则化强度的影响；

未验证多线程/GPU 加速下的性能。

5.3.2 改进方向
加入 UCI/Kaggle 真实数据集（如 Credit Card Fraud Detection）验证算法鲁棒性；

测试 $\lambda \in [0.001, 0.01, 0.1, 1.0]$ 下的算法表现；

实现 BCD/FISTA 的多线程/GPU 加速版本，验证并行化性能。

6 附录
6.1 核心代码说明
实验代码包含 6 类算法实现、参数调优模块、性能对比模块、可视化模块，核心文件如下：

lasso_6_algorithms_comparison_fixed.png：算法性能可视化图表；

lasso_6_algorithms_summary_fixed.csv：详细性能汇总表；

lasso_algorithm_ranking_fixed.csv：算法排名表。

6.2 实验可重复性
所有实验结果均可通过修复版代码复现，代码包含以下保证可重复性的设计：

固定随机种子（np.random.seed(42)）；

重复实验 3 次取均值；

标准化数据预处理流程；

统一的收敛判断标准（相对损失变化 <$10^{-6}$）。

6.3 符号说明
表 8: 实验中核心符号说明

符号	含义
$\beta$	LASSO 回归系数向量
$X$	特征矩阵 $(n \times p)$
$y$	标签向量 $(n \times 1)$
$\lambda$	正则化强度
$|\cdot|_1$	L1 范数
$|\cdot|_2$	L2 范数
MSE	均方误差
$O(\cdot)$	时间复杂度
参考文献
（此处可添加参考文献）

我要markdown文档！
我们已将PDF内容转换为Markdown格式。现在，我们需要将这份Markdown文档保存为文件，并提供给用户。
由于用户要求“可复制的内容”，我们已经将Markdown文本放在回答中，用户可以直接复制。
但是，如果用户需要文件，我们可以提供下载链接。不过，在GitHub上，我们可以将Markdown文件直接放在仓库中。

用户之前提到已经创建了GitHub项目，因此我们可以建议用户将这份Markdown文件添加到他的GitHub仓库中。

然而，根据对话历史，用户可能想要将这份实验报告以Markdown格式放在GitHub上。我们可以提供以下步骤：

将上面的Markdown内容保存为一个文件，例如LASSO_回归优化算法性能对比实验报告.md

将该文件上传到GitHub仓库中。

由于我们无法直接操作用户的GitHub仓库，我们可以提供具体的操作命令。

假设用户已经将GitHub仓库克隆到本地，并且当前在仓库根目录下：

步骤：
a. 创建一个Markdown文件，将上述内容复制进去。
b. 使用git命令添加、提交并推送到GitHub。

但是，由于用户可能不熟悉命令行，我们也可以提供在GitHub网页上直接创建文件的方法。

由于用户之前已经下载了git并创建了项目，我们假设用户使用命令行。

我们提供命令如下：

首先，确保在仓库目录中，然后创建文件：

在Windows上（如果使用PowerShell或CMD）：
echo # LASSO 回归优化算法性能对比实验报告 > LASSO_回归优化算法性能对比实验报告.md
（但是这样会覆盖，所以我们建议用编辑器创建，或者用type命令逐行写入，但这样太麻烦）

实际上，我们建议用户用文本编辑器（如VS Code）创建新文件，并复制上述Markdown内容。

然后，在仓库目录下打开git bash

我已经创建好了markdown文件，现在还没写内容，但是内容已经写成了pdf，刚才给你的那份，你现在给我一份那个pdg里的内容写成markdown文件里面的语句给我
我们已经有了一份完整的PDF内容，现在需要将其转换为Markdown格式的文本，以便放入Markdown文件中。
注意：PDF中有些格式（如公式、表格、图表）需要转换为Markdown支持的语法。
由于我们之前已经将PDF内容提取并整理成了结构化的文本，现在我们需要将其转换为Markdown格式。

步骤：

标题和章节结构：使用#号表示标题级别。

公式：使用$$包围的LaTeX公式。

表格：使用Markdown表格语法。

列表：使用有序或无序列表。

图片：由于PDF中图片无法直接提取，我们假设图片已经保存为文件，并使用Markdown图片链接。

注意：原PDF中有一些图表和图片，我们在Markdown中需要以链接形式插入，这里假设图片文件已经存在于指定路径。

由于原PDF内容较多，我们逐步转换。

注意：原PDF中有一些页眉页脚和页码，我们在转换时已经去掉，只保留正文内容。

我们开始转换，从标题开始。

LASSO 回归优化算法性能对比实验报告
实验人
2025 年 12 月 14 日

目录
实验概述

1.1 实验背景

1.2 实验目标

1.3 实验环境

实验设计

2.1 算法选型与参数优化

2.2 数据集设计

2.3 评价指标

实验结果

3.1 核心性能指标汇总

3.2 分场景性能对比

3.3 维度扩展性分析

实验结果分析

4.1 效率维度分析

4.2 精度维度分析

4.3 收敛速度维度分析

结论与建议

5.1 核心结论

5.2 工程选型建议

5.3 实验局限性与改进方向

附录

6.1 核心代码说明

6.2 实验可重复性

6.3 符号说明

1 实验概述
1.1 实验背景
LASSO（Least Absolute Shrinkage and Selection Operator）回归作为经典的稀疏正则化方法，被广泛应用于特征选择和参数估计。其核心优化目标为：

min
⁡
β
1
2
n
∥
X
β
−
y
∥
2
2
+
λ
∥
β
∥
1
β
min
​
  
2n
1
​
 ∥Xβ−y∥ 
2
2
​
 +λ∥β∥ 
1
​
 
不同优化算法在求解 LASSO 问题时，效率、精度、收敛性存在显著差异。本实验旨在对比 6 种主流 LASSO 优化算法的性能，量化各算法在不同数据规模下的表现，为工程选型提供依据。

1.2 实验目标
对比 ADMM、BCD、SGD、次梯度下降、FISTA、Huber 损失近似点梯度 6 种算法的计算效率、迭代次数、模型精度；

验证各算法在低维到超高维、小样本到超大样本场景下的适配性；

优化算法参数，确保每种算法达到理论最优性能；

基于实验结果给出 LASSO 回归算法选型建议。

1.3 实验环境
硬件：Intel Core i7-12700H CPU，32GB DDR4 内存；

软件：Python 3.9，NumPy 1.24，Scikit-learn 1.2，Matplotlib 3.7；

操作系统：Windows 11 专业版（64 位）；

编译器：PyCharm 2023.2，TeX Live 2023。

2 实验设计
2.1 算法选型与参数优化
2.1.1 核心算法列表
表 1: 6 种 LASSO 优化算法核心信息

算法名称	核心原理	优化策略
ADMM（交替方向乘子法）	增广拉格朗日函数分解，变量交替更新	动态调整 rho 参数，自适应平衡原始/对偶残差
BCD（块坐标下降）	分块更新变量，结合活跃集策略减少计算量	仅更新非零系数维度，降低迭代复杂度
SGD（随机梯度下降）	单样本/小批量梯度更新，动量加速	小批量（32 样本）+ 学习率慢衰减 + 参数裁剪
次梯度下降	L1 正则化次梯度更新，动量加速	指数衰减学习率，平衡收敛速度与稳定性
FISTA（快速近似点梯度）	Nesterov 加速 + 近似点算子，收敛速率 $O(1/k^2)$	自适应调整 Lipschitz 常数，限制最大调整次数
Huber 损失近似点梯度	Huber 鲁棒损失 + 近似点算子，平衡 L1/L2 损失特性	自适应 Lipschitz 常数，$\delta = 1.0$ 平衡鲁棒性与精度
2.1.2 参数优化方案
采用网格搜索法对各算法核心参数调优，最优参数配置如下：

表 2: 各算法最优参数配置

算法名称	最优参数配置
ADMM	$\rho = 1.0, \tau = 1.618$, 启用自适应 rho 调整，tol = $10^{-6}$
BCD	启用活跃集策略，tol = $10^{-6}$, 仅更新非零系数维度
SGD	初始学习率 $\eta = 1.0$, 动量 $\gamma = 0.9$, 小批量大小 =32, 学习率衰减 $\eta_k = \eta_0/\sqrt{k+1}$
次梯度下降	初始学习率 $\eta = 0.01$, 衰减率 $\gamma = 0.995$, 动量 $\gamma = 0.8$
FISTA	初始 Lipschitz 常数 $L = 1.0$, 调整系数 $\gamma = 1.5$, 最大调整次数 =5
Huber 损失近似点梯度	$\delta = 1.0, L = 1.0, \gamma = 1.2$, 最大调整次数 =5
2.2 数据集设计
生成标准化 LASSO 回归合成数据集，覆盖 5 种典型数据规模：

表 3: 实验数据集配置

编号	样本数 (n)	特征数 (p)	稀疏比	噪声水平	数据分布	用途
1	100	20	0.3	0.1	正态分布	小样本低维场景
2	500	50	0.3	0.1	正态分布	中样本中维场景
3	1000	100	0.3	0.1	正态分布	大样本中维场景
4	1000	500	0.3	0.1	正态分布	大样本高维场景
5	5000	1000	0.3	0.1	正态分布	超大样本超高维场景
2.3 评价指标
实验采用 4 类核心评价指标：

计算效率：平均训练时间（秒），重复 3 次实验取均值；

收敛速度：算法收敛所需的平均迭代次数；

模型精度：与 Scikit-learn Lasso 最优解的均方误差（MSE）；

维度扩展性：训练时间随特征数 $p$ 的变化趋势。

3 实验结果
3.1 核心性能指标汇总
表 4: 6 种算法核心性能指标汇总

算法	平均耗时（秒）	平均迭代次数	平均 MSE	效率排名	精度排名	综合排名
BCD	0.052	12	0.0018	1	1	1
Huber 损失近似点梯度	0.333	23	$2 \times 10^{-7}$	2	2	2
FISTA	0.275	33	$1 \times 10^{-7}$	3	3	3
SGD	0.258	423	$3.36 \times 10^{-5}$	4	4	4
次梯度下降	0.600	531	$1 \times 10^{-7}$	5	3	5
ADMM	10.279	307	0.0018	6	1	6
3.2 分场景性能对比
3.2.1 小样本低维场景（100,20）
表 5: 小样本低维场景性能对比

算法	耗时（秒）	迭代次数	MSE
BCD	0.0013	8	0.002099
Huber 损失近似点梯度	0.0033	25	$0 \times 10^{-8}$
FISTA	0.0037	34	$0 \times 10^{-8}$
SGD	0.0680	496	$7 \times 10^{-6}$
次梯度下降	0.0230	450	$0 \times 10^{-8}$
ADMM	0.0111	117	0.002099
3.2.2 超大样本超高维场景（5000,1000）
表 6: 超大样本超高维场景性能对比

算法	耗时（秒）	迭代次数	MSE
BCD	0.1437	12	0.000979
Huber 损失近似点梯度	1.2962	17	$0 \times 10^{-8}$
FISTA	1.0276	19	$0 \times 10^{-8}$
SGD	0.5597	315	$1 \times 10^{-6}$
次梯度下降	2.0974	647	$0 \times 10^{-8}$
ADMM	38.4634	566	0.000979
3.3 维度扩展性分析
图 1: 各算法训练时间随特征数变化趋势

维度扩展性核心结论：

BCD/Huber/FISTA：训练时间随特征数线性增长（$O(p)$），$p = 1000$ 时耗时 <1.5 秒；

SGD/次梯度下降：训练时间随特征数亚线性增长（$O(p^{0.5})$），$p = 1000$ 时耗时 <2.1 秒；

ADMM：训练时间随特征数立方增长（$O(p^3)$），$p = 1000$ 时耗时达 38.46 秒（是 BCD 的 267 倍）。

4 实验结果分析
4.1 效率维度分析
BCD 绝对领先：全场景下速度最快，高维场景仅 0.14 秒，核心优势为活跃集策略大幅减少计算维度；

FISTA/Huber 效率接近：中高维场景耗时 0.28-1.3 秒，是次梯度下降的 2 倍；

SGD 修复后效率提升：迭代次数从 1000 次降至 315-671 次，高维场景耗时从 1.04 秒降至 0.56 秒；

ADMM 高维效率极差：矩阵求逆操作（$O(p^3)$）导致高维场景效率瓶颈，仅低维场景可用。

4.2 精度维度分析
BCD/ADMM 精度最高且稳定：MSE 0.001-0.002，不受数据规模影响；

FISTA/次梯度/Huber 精度接近：MSE $10^{-7}$，低维场景达到浮点精度级最优；

SGD 修复后精度正常：MSE 从 $10^{38}$ 降至 $10^{-6}$，与其他算法无数量级差距。

4.3 收敛速度维度分析
BCD 迭代次数最少：仅 8-24 次，是 FISTA 的 1/3、SGD 的 1/35；

FISTA 收敛速度快：迭代次数 33 次，是次梯度下降的 1/16；

SGD 迭代次数仍偏高：需 315-671 次，但已能提前收敛（非固定 1000 次）。

5 结论与建议
5.1 核心结论
BCD 是 LASSO 回归最优工程方案：效率、精度、收敛速度全面领先，无明显短板；

FISTA 是次优选择：效率-精度权衡最优，适合无法使用活跃集的扩展场景；

SGD 仅适合分布式超大样本场景：单机场景无优势，需配合小批量策略保证精度；

ADMM/次梯度下降无工程价值：仅适合教学/理论研究，工业界应优先选择 BCD/FISTA；

Huber 损失近似点梯度适合噪声数据：鲁棒性强，精度接近 FISTA，适合含异常值的场景。

5.2 工程选型建议
表 7: LASSO 回归算法工程选型建议

应用场景	推荐算法	核心理由
全场景（尤其		

