# LASSO 回归优化算法性能对比实验报告

## 王明宽 赵许晴
2025 年 12 月 14 日

## 目录
1. [实验概述](#1-实验概述)
    - [1.1 实验背景](#11-实验背景)
    - [1.2 实验目标](#12-实验目标)
    - [1.3 实验环境](#13-实验环境)
2. [实验设计](#2-实验设计)
    - [2.1 算法选型与参数优化](#21-算法选型与参数优化)
    - [2.2 数据集设计](#22-数据集设计)
    - [2.3 评价指标](#23-评价指标)
3. [实验结果](#3-实验结果)
    - [3.1 核心性能指标汇总](#31-核心性能指标汇总)
    - [3.2 分场景性能对比](#32-分场景性能对比)
    - [3.3 维度扩展性分析](#33-维度扩展性分析)
4. [实验结果分析](#4-实验结果分析)
    - [4.1 效率维度分析](#41-效率维度分析)
    - [4.2 精度维度分析](#42-精度维度分析)
    - [4.3 收敛速度维度分析](#43-收敛速度维度分析)
5. [结论与建议](#5-结论与建议)
    - [5.1 核心结论](#51-核心结论)
    - [5.2 工程选型建议](#52-工程选型建议)
    - [5.3 实验局限性与改进方向](#53-实验局限性与改进方向)
6. [附录](#6-附录)
    - [6.1 核心代码说明](#61-核心代码说明)
    - [6.2 实验可重复性](#62-实验可重复性)
    - [6.3 符号说明](#63-符号说明)

---
# 1 实验概述

## 1.1 实验背景

LASSO（Least Absolute Shrinkage and Selection Operator）回归作为经典的稀疏正则化方法，被广泛应用于特征选择和参数估计。其核心优化目标为：

$$\min_{\beta} \frac{1}{2n} \| X\beta - y \|_2^2 + \lambda \| \beta \|_1$$

不同优化算法在求解 LASSO 问题时，效率、精度、收敛性存在显著差异。本实验旨在对比 6 种主流 LASSO 优化算法的性能，量化各算法在不同数据规模下的表现，为工程选型提供依据。

## 1.2 实验目标

1. 对比 ADMM、BCD、SGD、次梯度下降、FISTA、Huber 损失近似点梯度 6 种算法的计算效率、迭代次数、模型精度；
2. 验证各算法在低维到超高维、小样本到超大样本场景下的适配性；
3. 优化算法参数，确保每种算法达到理论最优性能；
4. 基于实验结果给出 LASSO 回归算法选型建议。


### 1.3 实验环境

- **硬件**：Intel Core i7-12700H CPU，32GB DDR4 内存；
- **软件**：Python 3.9，NumPy 1.24，Scikit-learn 1.2，Matplotlib 3.7；
- **操作系统**：Windows 11 专业版（64 位）；
- **编译器**：PyCharm 2023.2，TeX Live 2023。

---

## 2 实验设计

### 2.1 算法选型与参数优化

#### 2.1.1 核心算法列表

**表 1: 6 种 LASSO 优化算法核心信息**

| 算法名称 | 核心原理 | 优化策略 |
|---------|---------|---------|
| ADMM（交替方向乘子法） | 增广拉格朗日函数分解，变量交替更新 | 动态调整 rho 参数，自适应平衡原始/对偶残差 |
| BCD（块坐标下降） | 分块更新变量，结合活跃集策略减少计算量 | 仅更新非零系数维度，降低迭代复杂度 |
| SGD（随机梯度下降） | 单样本/小批量梯度更新，动量加速 | 小批量（32 样本）+ 学习率慢衰减 + 参数裁剪 |
| 次梯度下降 | L1 正则化次梯度更新，动量加速 | 指数衰减学习率，平衡收敛速度与稳定性 |
| FISTA（快速近似点梯度） | Nesterov 加速 + 近似点算子，收敛速率 O(1/k²) | 自适应调整 Lipschitz 常数，限制最大调整次数 |
| Huber 损失近似点梯度 | Huber 鲁棒损失 + 近似点算子，平衡 L1/L2 损失特性 | 自适应 Lipschitz 常数，δ = 1.0 平衡鲁棒性与精度 |

#### 2.1.2 参数优化方案

采用网格搜索法对各算法核心参数调优，最优参数配置如下：

**表 2: 各算法最优参数配置**

| 算法名称 | 最优参数配置 |
|---------|-------------|
| ADMM | ρ = 1.0, τ = 1.618, 启用自适应 rho 调整，tol = 10⁻⁶ |
| BCD | 启用活跃集策略，tol = 10⁻⁶, 仅更新非零系数维度 |
| SGD | 初始学习率 η = 1.0, 动量 γ = 0.9, 小批量大小 =32, 学习率衰减 η_k = η₀/√(k+1) |
| 次梯度下降 | 初始学习率 η = 0.01, 衰减率 γ = 0.995, 动量 γ = 0.8 |
| FISTA | 初始 Lipschitz 常数 L = 1.0, 调整系数 γ = 1.5, 最大调整次数 =5 |
| Huber 损失近似点梯度 | δ = 1.0, L = 1.0, γ = 1.2, 最大调整次数 =5 |

### 2.2 数据集设计

生成标准化 LASSO 回归合成数据集，覆盖 5 种典型数据规模：

**表 3: 实验数据集配置**

| 编号 | 样本数 (n) | 特征数 (p) | 稀疏比 | 噪声水平 | 数据分布 | 用途 |
|------|-----------|-----------|--------|---------|---------|------|
| 1 | 100 | 20 | 0.3 | 0.1 | 正态分布 | 小样本低维场景 |
| 2 | 500 | 50 | 0.3 | 0.1 | 正态分布 | 中样本中维场景 |
| 3 | 1000 | 100 | 0.3 | 0.1 | 正态分布 | 大样本中维场景 |
| 4 | 1000 | 500 | 0.3 | 0.1 | 正态分布 | 大样本高维场景 |
| 5 | 5000 | 1000 | 0.3 | 0.1 | 正态分布 | 超大样本超高维场景 |

### 2.3 评价指标

实验采用 4 类核心评价指标：

1. **计算效率**：平均训练时间（秒），重复 3 次实验取均值；
2. **收敛速度**：算法收敛所需的平均迭代次数；
3. **模型精度**：与 Scikit-learn Lasso 最优解的均方误差（MSE）；
4. **维度扩展性**：训练时间随特征数 p 的变化趋势。

---

## 3 实验结果

### 3.1 核心性能指标汇总

**表 4: 6 种算法核心性能指标汇总**

| 算法 | 平均耗时（秒） | 平均迭代次数 | 平均 MSE | 效率排名 | 精度排名 | 综合排名 |
|------|---------------|-------------|----------|----------|----------|----------|
| BCD | 0.052 | 12 | 0.0018 | 1 | 1 | 1 |
| Huber 损失近似点梯度 | 0.333 | 23 | 2×10⁻⁷ | 2 | 2 | 2 |
| FISTA | 0.275 | 33 | 1×10⁻⁷ | 3 | 3 | 3 |
| SGD | 0.258 | 423 | 3.36×10⁻⁵ | 4 | 4 | 4 |
| 次梯度下降 | 0.600 | 531 | 1×10⁻⁷ | 5 | 3 | 5 |
| ADMM | 10.279 | 307 | 0.0018 | 6 | 1 | 6 |

### 3.2 分场景性能对比

#### 3.2.1 小样本低维场景（100,20）

**表 5: 小样本低维场景性能对比**

| 算法 | 耗时（秒） | 迭代次数 | MSE |
|------|-----------|---------|------|
| BCD | 0.0013 | 8 | 0.002099 |
| Huber 损失近似点梯度 | 0.0033 | 25 | 0×10⁻⁸ |
| FISTA | 0.0037 | 34 | 0×10⁻⁸ |
| SGD | 0.0680 | 496 | 7×10⁻⁶ |
| 次梯度下降 | 0.0230 | 450 | 0×10⁻⁸ |
| ADMM | 0.0111 | 117 | 0.002099 |

#### 3.2.2 超大样本超高维场景（5000,1000）

**表 6: 超大样本超高维场景性能对比**

| 算法 | 耗时（秒） | 迭代次数 | MSE |
|------|-----------|---------|------|
| BCD | 0.1437 | 12 | 0.000979 |
| Huber 损失近似点梯度 | 1.2962 | 17 | 0×10⁻⁸ |
| FISTA | 1.0276 | 19 | 0×10⁻⁸ |
| SGD | 0.5597 | 315 | 1×10⁻⁶ |
| 次梯度下降 | 2.0974 | 647 | 0×10⁻⁸ |
| ADMM | 38.4634 | 566 | 0.000979 |

### 3.3 维度扩展性分析

**图 1: 各算法训练时间随特征数变化趋势**

维度扩展性核心结论：

- **BCD/Huber/FISTA**：训练时间随特征数线性增长（O(p)），p = 1000 时耗时 <1.5 秒；
- **SGD/次梯度下降**：训练时间随特征数亚线性增长（O(p^0.5)），p = 1000 时耗时 <2.1 秒；
- **ADMM**：训练时间随特征数立方增长（O(p³)），p = 1000 时耗时达 38.46 秒（是 BCD 的 267 倍）。

---

## 4 实验结果分析

### 4.1 效率维度分析

1. **BCD 绝对领先**：全场景下速度最快，高维场景仅 0.14 秒，核心优势为活跃集策略大幅减少计算维度；
2. **FISTA/Huber 效率接近**：中高维场景耗时 0.28-1.3 秒，是次梯度下降的 2 倍；
3. **SGD 修复后效率提升**：迭代次数从 1000 次降至 315-671 次，高维场景耗时从 1.04 秒降至 0.56 秒；
4. **ADMM 高维效率极差**：矩阵求逆操作（O(p³)）导致高维场景效率瓶颈，仅低维场景可用。

### 4.2 精度维度分析

1. **BCD/ADMM 精度最高且稳定**：MSE 0.001-0.002，不受数据规模影响；
2. **FISTA/次梯度/Huber 精度接近**：MSE 10⁻⁷，低维场景达到浮点精度级最优；
3. **SGD 修复后精度正常**：MSE 从 10³⁸ 降至 10⁻⁶，与其他算法无数量级差距。

### 4.3 收敛速度维度分析

1. **BCD 迭代次数最少**：仅 8-24 次，是 FISTA 的 1/3、SGD 的 1/35；
2. **FISTA 收敛速度快**：迭代次数 33 次，是次梯度下降的 1/16；
3. **SGD 迭代次数仍偏高**：需 315-671 次，但已能提前收敛（非固定 1000 次）。

---

## 5 结论与建议

### 5.1 核心结论

1. **BCD 是 LASSO 回归最优工程方案**：效率、精度、收敛速度全面领先，无明显短板；
2. **FISTA 是次优选择**：效率-精度权衡最优，适合无法使用活跃集的扩展场景；
3. **SGD 仅适合分布式超大样本场景**：单机场景无优势，需配合小批量策略保证精度；
4. **ADMM/次梯度下降无工程价值**：仅适合教学/理论研究，工业界应优先选择 BCD/FISTA；
5. **Huber 损失近似点梯度适合噪声数据**：鲁棒性强，精度接近 FISTA，适合含异常值的场景。

### 5.2 工程选型建议

**表 7: LASSO 回归算法工程选型建议**

| 应用场景 | 推荐算法 | 核心理由 |
|----------|----------|----------|
| 全场景（尤其高维） | BCD | 速度最快、精度最高、迭代次数最少 |
| 高维大数据 + 实时性要求高 | FISTA | 效率-精度权衡最优、易实现、收敛速度快 |
| 含异常值/噪声数据 | Huber 损失近似点梯度 | 鲁棒性强、精度接近 FISTA |
| 分布式超大样本(n>10 万) | SGD | 易并行化、内存占用低，配合小批量策略保证精度 |
| 低维 + 超高精度要求 | ADMM | 收敛理论保证强、精度稳定（仅低维场景推荐） |
| 教学演示/简单场景 | 次梯度下降 | 实现最简单、理论门槛低 |

### 5.3 实验局限性与改进方向

#### 5.3.1 局限性

1. 仅使用合成数据集，未验证真实数据集（如金融/医疗数据）；
2. 正则化强度固定（λ = 0.1），未测试不同正则化强度的影响；
3. 未验证多线程/GPU 加速下的性能。

#### 5.3.2 改进方向

1. 加入 UCI/Kaggle 真实数据集（如 Credit Card Fraud Detection）验证算法鲁棒性；
2. 测试 λ ∈ [0.001, 0.01, 0.1, 1.0] 下的算法表现；
3. 实现 BCD/FISTA 的多线程/GPU 加速版本，验证并行化性能。

---

## 6 附录

### 6.1 核心代码说明

实验代码包含 6 类算法实现、参数调优模块、性能对比模块、可视化模块，核心文件如下：

- **`lasso_6_algorithms_comparison_fixed.png`**：算法性能可视化图表；
- **`lasso_6_algorithms_summary_fixed.csv`**：详细性能汇总表；
- **`lasso_algorithm_ranking_fixed.csv`**：算法排名表。

### 6.2 实验可重复性

所有实验结果均可通过修复版代码复现，代码包含以下保证可重复性的设计：

1. 固定随机种子（`np.random.seed(42)`）；
2. 重复实验 3 次取均值；
3. 标准化数据预处理流程；
4. 统一的收敛判断标准（相对损失变化 <10⁻⁶）。

### 6.3 符号说明

**表 8: 实验中核心符号说明**

| 符号 | 含义 |
|------|------|
| β | LASSO 回归系数向量 |
| X | 特征矩阵 (n×p) |
| y | 标签向量 (n×1) |
| λ | 正则化强度 |
| ‖·‖₁ | L1 范数 |
| ‖·‖₂ | L2 范数 |
| MSE | 均方误差 |
| O(·) | 时间复杂度 |
